{
 "cells": [
  {
   "cell_type": "raw",
   "id": "36ba384c",
   "metadata": {},
   "source": [
    "# 读取app key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3af6d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "def get_key(app):\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('../../key/config.ini')\n",
    "    api_key = config.get(app, 'api_key')\n",
    "    return api_key\n",
    "\n",
    "def get_gaode_key():\n",
    "    return get_key(\"GaoDe\")\n",
    "\n",
    "def get_openai_key():\n",
    "    return get_key(\"OpenAI\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c0fb8d5e",
   "metadata": {},
   "source": [
    "封装GPT调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb083acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = get_openai_key()#填充自己的key\n",
    "\n",
    "def get_completion(prompt, model):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84c6ecdb",
   "metadata": {},
   "source": [
    "读一篇短篇小说《命若琴弦》，内容长度12627子，超过4Ktoken，不足16K的token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1469a0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12627\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "text_mrqx = requests.get(\"https://raw.githubusercontent.com/hankinghu/literature-books/master/命若琴弦.txt\").text\n",
    "\n",
    "prompt =f'''请简要以下小说\n",
    "\n",
    "{text_mrqx[235:-145]}\n",
    "'''\n",
    "\n",
    "print(len(text_mrqx))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "345afd5e",
   "metadata": {},
   "source": [
    "用gpt-3.5-turbo基础模型执行，报错token超限"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9b09a375",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens. However, your messages resulted in 16135 tokens. Please reduce the length of the messages.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mget_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[110], line 7\u001b[0m, in \u001b[0;36mget_completion\u001b[0;34m(prompt, model)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_completion\u001b[39m(prompt, model):\n\u001b[1;32m      6\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}]\n\u001b[0;32m----> 7\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/openai/api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    613\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    614\u001b[0m         )\n\u001b[1;32m    615\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    616\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    625\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    626\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/openai/api_requestor.py:682\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    680\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    683\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens. However, your messages resulted in 16135 tokens. Please reduce the length of the messages."
     ]
    }
   ],
   "source": [
    "print(get_completion(prompt,model=\"gpt-3.5-turbo\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3108d626",
   "metadata": {},
   "source": [
    "调用gpt-3.5-turbo-16k模型，可以正常输给。16K的token下可以做的事情真的就很多了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee73d2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这个故事讲述了两个瞎子，一老一少，他们在偏僻的群山中走动，以说书为生。老瞎子希望能弹断一千根琴弦，以实现他的愿望。他们来到野羊坳村，小瞎子遇到了一个叫兰秀儿的女孩，他们之间产生了感情。然而，老瞎子意识到这段感情可能会给他们带来麻烦，他决定离开野羊坳。在离开之前，他弹断了最后几根琴弦。然后，老瞎子离开了，留下了小瞎子和兰秀儿。小瞎子病倒了，但他仍然等待着老瞎子的回\n"
     ]
    }
   ],
   "source": [
    "print(get_completion(prompt,model=\"gpt-3.5-turbo-16k\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "71ec7dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import requests\n",
    "openai.api_key = get_openai_key()\n",
    "\n",
    "\n",
    "#调用GPT模型\n",
    "def get_completion_from_messages(messages,functions, model=\"gpt-3.5-turbo-0613\", temperature=0):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "        functions=functions\n",
    "    )\n",
    "    return response.choices[0]\n",
    "\n",
    "\n",
    "def get_current_weather(para):\n",
    "    city = para[\"city\"]\n",
    "    url = f'https://restapi.amap.com/v3/weather/weatherInfo?parameters'\n",
    "    params = {\n",
    "        'key': get_gaode_key(),\n",
    "        'city': city,\n",
    "        'extensions': 'base',\n",
    "        'output': 'JSON',\n",
    "        'extensions':'all'\n",
    "        \n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    return data['forecasts'][0]['casts'][0]\n",
    "\n",
    "def send_email(para):\n",
    "    addr = para[\"addr\"]\n",
    "    title = para[\"title\"]\n",
    "    content = para[\"content\"]\n",
    "    text = f\"To {addr}\\n{title}\\n{content}\"\n",
    "    #print(\"邮件已经发送：\\n \"+text)\n",
    "    return {\"status\":\"邮件已经发送\",\"email\":text}\n",
    "\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"获取一个城市的当前天气\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"city\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"城市名称\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"city\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"send_email\",\n",
    "        \"description\": \"给指定地址发送电子邮件\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"addr\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"电子邮件地址\"\n",
    "                },\n",
    "                \"title\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"邮件标题\"\n",
    "                },\n",
    "                \"content\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"邮件内容\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"addr\",\"title\",\"content\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "#向GPT提问\n",
    "def get_completion(prompt,functions):\n",
    "    #拼接消息\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    #第一轮调用GPT\n",
    "    response = get_completion_from_messages(messages,functions)\n",
    "    \n",
    "    #如果返回终止原因是API调用，本地执行\n",
    "    if response['finish_reason'] == \"function_call\":   \n",
    "        arguments = response[\"message\"][\"function_call\"][\"arguments\"]\n",
    "        function =  response[\"message\"][\"function_call\"][\"name\"]\n",
    "\n",
    "        result = eval(f\"{function}({arguments})\")#根据API名称和参数动态调用本地接口\n",
    "        \n",
    "        #把GPT的调用指令和API返回结果再次发送给GPT\n",
    "        messages.append(response[\"message\"])\n",
    "        messages.append( {\"role\": \"function\", \"name\": \"get_current_weather\", \"content\":str(result)})\n",
    "        response = get_completion_from_messages(messages,functions)\n",
    "        \n",
    "    print(response[\"message\"][\"content\"])\n",
    "    \n",
    "\n",
    "get_completion(\"我在杭州,今天出门要带伞吗\",functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972ed3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fb84b652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据当前天气情况，杭州今天有小雨，建议您出门时带上一把伞。\n"
     ]
    }
   ],
   "source": [
    "get_completion(\"我在杭州,今天出门要带伞吗\",functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3df15db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "邮件已经发送至 runing@spaceK.com，邮件标题为 \"市场营销部门周会通知\"，邮件内容如下：\n",
      "\n",
      "尊敬的市场营销部门成员，\n",
      "\n",
      "本周会将于下周二14点在蓝色宇宙会议室举行。\n",
      "\n",
      "会议主题是618大促简要复盘，请大家准时参加。\n",
      "\n",
      "谢谢！\n",
      "\n",
      "市场营销部门\n"
     ]
    }
   ],
   "source": [
    "get_completion(\"帮我发一封市场营销部门周会邮件，内容包含周会时间、地点、主题，周会时间是下周二14点，地点在蓝色宇宙会议室，主题是618大促简要复盘，部门邮件地址是runing@spaceK.com\",functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "aa47ac24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据当前天气情况，长沙今天有小雨，建议您出门时带上一把伞。\n"
     ]
    }
   ],
   "source": [
    "get_completion(\"我在长沙,今天出门要带伞吗\",functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b88ebbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据成都的天气预报，今天是多云的天气，白天最高温度为28℃，夜间最低温度为21℃。不需要带伞。\n"
     ]
    }
   ],
   "source": [
    "get_completion(\"我在成都,今天出门要带伞吗\",functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cac0044d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "输入messages:[\n",
      " {\n",
      "  \"role\": \"user\",\n",
      "  \"content\": \"我在成都,今天出门要带伞吗\"\n",
      " }\n",
      "]\n",
      "输入functions:[\n",
      " {\n",
      "  \"name\": \"get_current_weather\",\n",
      "  \"description\": \"获取一个城市的当前天气\",\n",
      "  \"parameters\": {\n",
      "   \"type\": \"object\",\n",
      "   \"properties\": {\n",
      "    \"city\": {\n",
      "     \"type\": \"string\",\n",
      "     \"description\": \"城市名称\"\n",
      "    }\n",
      "   },\n",
      "   \"required\": [\n",
      "    \"city\"\n",
      "   ]\n",
      "  }\n",
      " }\n",
      "]\n",
      "输出:{\n",
      " \"id\": \"chatcmpl-7SPqEy1Iz16iVwHVpE2jwpECvaehw\",\n",
      " \"object\": \"chat.completion\",\n",
      " \"created\": 1687006874,\n",
      " \"model\": \"gpt-3.5-turbo-0613\",\n",
      " \"choices\": [\n",
      "  {\n",
      "   \"index\": 0,\n",
      "   \"message\": {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": null,\n",
      "    \"function_call\": {\n",
      "     \"name\": \"get_current_weather\",\n",
      "     \"arguments\": \"{\\n  \\\"city\\\": \\\"成都\\\"\\n}\"\n",
      "    }\n",
      "   },\n",
      "   \"finish_reason\": \"function_call\"\n",
      "  }\n",
      " ],\n",
      " \"usage\": {\n",
      "  \"prompt_tokens\": 73,\n",
      "  \"completion_tokens\": 17,\n",
      "  \"total_tokens\": 90\n",
      " }\n",
      "}\n",
      "-----------------------------------------\n",
      "输入messages:[\n",
      " {\n",
      "  \"role\": \"user\",\n",
      "  \"content\": \"我在成都,今天出门要带伞吗\"\n",
      " },\n",
      " {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": null,\n",
      "  \"function_call\": {\n",
      "   \"name\": \"get_current_weather\",\n",
      "   \"arguments\": \"{\\n  \\\"city\\\": \\\"成都\\\"\\n}\"\n",
      "  }\n",
      " },\n",
      " {\n",
      "  \"role\": \"function\",\n",
      "  \"name\": \"get_current_weather\",\n",
      "  \"content\": \"{'date': '2023-06-17', 'week': '6', 'dayweather': '多云', 'nightweather': '多云', 'daytemp': '28', 'nighttemp': '21', 'daywind': '东北', 'nightwind': '东北', 'daypower': '≤3', 'nightpower': '≤3', 'daytemp_float': '28.0', 'nighttemp_float': '21.0'}\"\n",
      " }\n",
      "]\n",
      "输入functions:[\n",
      " {\n",
      "  \"name\": \"get_current_weather\",\n",
      "  \"description\": \"获取一个城市的当前天气\",\n",
      "  \"parameters\": {\n",
      "   \"type\": \"object\",\n",
      "   \"properties\": {\n",
      "    \"city\": {\n",
      "     \"type\": \"string\",\n",
      "     \"description\": \"城市名称\"\n",
      "    }\n",
      "   },\n",
      "   \"required\": [\n",
      "    \"city\"\n",
      "   ]\n",
      "  }\n",
      " }\n",
      "]\n",
      "输出:{\n",
      " \"id\": \"chatcmpl-7SPqGUfxgozkhDAoOjEPO1NwUWCan\",\n",
      " \"object\": \"chat.completion\",\n",
      " \"created\": 1687006876,\n",
      " \"model\": \"gpt-3.5-turbo-0613\",\n",
      " \"choices\": [\n",
      "  {\n",
      "   \"index\": 0,\n",
      "   \"message\": {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"根据成都的天气预报，今天是多云的天气，白天最高温度为28摄氏度，夜间最低温度为21摄氏度。不需要带伞出门。\"\n",
      "   },\n",
      "   \"finish_reason\": \"stop\"\n",
      "  }\n",
      " ],\n",
      " \"usage\": {\n",
      "  \"prompt_tokens\": 202,\n",
      "  \"completion_tokens\": 66,\n",
      "  \"total_tokens\": 268\n",
      " }\n",
      "}\n",
      "根据成都的天气预报，今天是多云的天气，白天最高温度为28摄氏度，夜间最低温度为21摄氏度。不需要带伞出门。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "openai.api_key = get_openai_key()\n",
    "\n",
    "\n",
    "import requests\n",
    "def get_current_weather(para):\n",
    "    #获取当天的天气预报\n",
    "    city = para[\"city\"]\n",
    "    url = f'https://restapi.amap.com/v3/weather/weatherInfo?parameters'\n",
    "    params = {\n",
    "        'key': get_gaode_key(),#填入自己的高德API\n",
    "        'city': city,\n",
    "        'extensions': 'base',\n",
    "        'output': 'JSON',\n",
    "        'extensions':'all'\n",
    "        \n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    return data['forecasts'][0]['casts'][0]\n",
    "\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"获取一个城市的当前天气\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"city\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"城市名称\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"city\"]\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "import openai\n",
    "import json\n",
    "\n",
    "#调用GPT模型\n",
    "def get_completion_from_messages(messages,functions, model=\"gpt-3.5-turbo-0613\", temperature=0):\n",
    "    print(\"-----------------------------------------\\n输入messages:\"+str(json.dumps(messages, indent=1, ensure_ascii=False)))\n",
    "    print(\"输入functions:\"+str(json.dumps(functions, indent=1, ensure_ascii=False)))\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "        functions=functions\n",
    "    )\n",
    "    \n",
    "    print(\"输出:\"+json.dumps(response, indent=1, ensure_ascii=False))\n",
    "    return response.choices[0]\n",
    "\n",
    "\n",
    "\n",
    "#向GPT提问\n",
    "def ask_gpt(prompt,functions):\n",
    "    #拼接消息\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    #第一轮调用GPT\n",
    "    response = get_completion_from_messages(messages,functions)\n",
    "    \n",
    "    #如果返回终止原因是API调用，本地执行\n",
    "    if response['finish_reason'] == \"function_call\":   \n",
    "        arguments = response[\"message\"][\"function_call\"][\"arguments\"]\n",
    "        function =  response[\"message\"][\"function_call\"][\"name\"]\n",
    "\n",
    "        result = eval(f\"{function}({arguments})\")#根据API名称和参数动态调用本地接口\n",
    "        \n",
    "        #把GPT的调用指令和API返回结果再次发送给GPT\n",
    "        messages.append(response[\"message\"])\n",
    "        messages.append( {\"role\": \"function\", \"name\": \"get_current_weather\", \"content\":str(result)})\n",
    "        response = get_completion_from_messages(messages,functions)\n",
    "        \n",
    "    print(response[\"message\"][\"content\"])\n",
    "\n",
    "get_completion(\"我在成都,今天出门要带伞吗\",functions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "08c4f4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': '2023-06-17', 'week': '6', 'dayweather': '多云', 'nightweather': '晴', 'daytemp': '38', 'nighttemp': '22', 'daywind': '东南', 'nightwind': '东南', 'daypower': '≤3', 'nightpower': '≤3', 'daytemp_float': '38.0', 'nighttemp_float': '22.0'}\n"
     ]
    }
   ],
   "source": [
    "print(get_current_weather({\"city\":\"北京\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897c6c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
